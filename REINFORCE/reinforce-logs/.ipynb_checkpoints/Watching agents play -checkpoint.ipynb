{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714b8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "#class for the neural network\n",
    "class neural_network(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        #get number of actions & observations for output & input layer resp.\n",
    "        self.n_actions = 3\n",
    "        self.n_observations = 900\n",
    "        print(\"Number actions: \" + str(self.n_actions))\n",
    "        print(\"Number observations: \" + str(self.n_observations))\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2, out_channels=8, kernel_size=4, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=8, out_channels = 4, kernel_size=4, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(324, 160),\n",
    "            nn.ReLU(),\n",
    "           # nn.Linear(800, 400),\n",
    "            nn.Linear(160, self.n_actions),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 324)  # reduce the dimensions for linear layer input\n",
    "        x = x.squeeze(0)\n",
    "        return self.classifier(x)\n",
    "                    \n",
    "    def predict(self, state):\n",
    "        #print(type(state))\n",
    "        action_probabilities = self.forward(state)\n",
    "        return action_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f7f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\seeding.py:138: DeprecationWarning: \u001b[33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "C:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\seeding.py:175: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number actions: 3\n",
      "Number observations: 900\n",
      "EPISODE 0\n",
      "EPISODE 1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import functional\n",
    "import math\n",
    "import random\n",
    "\n",
    "available_actions = [0,2,3]\n",
    "\n",
    "state = []\n",
    "\n",
    "def process(rgb):\n",
    "    frame = rgb[34:194][:][:]\n",
    "    transposed = frame.transpose(2, 0, 1)\n",
    "    as_tensor = torch.Tensor(transposed)\n",
    "    grey = functional.rgb_to_grayscale(as_tensor)\n",
    "    downsampled = functional.resize(grey, [84, 84])\n",
    "    thresh = nn.Threshold(87.3, 0)\n",
    "    background_removed = thresh(downsampled)\n",
    "    state.append(background_removed)\n",
    "    \n",
    "    if (len(state) > 2):\n",
    "        state.pop(0)\n",
    "    #print(numpy.shape(torch.flatten(torch.stack(state).squeeze(1), 0, -1)))\n",
    "    return torch.stack(state).squeeze(1)\n",
    "\n",
    "env = gym.make('ALE/Pong-v5', frameskip=4, difficulty=0)\n",
    "\n",
    "saved_network = neural_network(env)\n",
    "saved_network.load_state_dict(torch.load('reinforce-logs/agent1.pt'))\n",
    "\n",
    "observation = env.reset()\n",
    "cur_state = process(observation)\n",
    "\n",
    "for episode in range(10):\n",
    "    print(\"EPISODE \" + str(episode))\n",
    "    cur_state = process(env.reset())\n",
    "    done = False\n",
    "    rewards = [0]\n",
    "    \n",
    "    while not done:\n",
    "        action_probs = saved_network.predict(cur_state)\n",
    "        action = random.choices(available_actions, weights=action_probs.tolist())[0]\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if reward == 0:\n",
    "            rewards[-1] += 1\n",
    "        else:\n",
    "            re\n",
    "        cur_state = process(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08816257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
